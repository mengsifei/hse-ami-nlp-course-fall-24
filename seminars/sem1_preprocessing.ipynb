{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpq6g7racZ65"
      },
      "source": [
        "# Инструменты для работы с языком"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x57fns1XcZ7E"
      },
      "source": [
        "... или зачем нужна предобработка.\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10_Aehfbxgr3fxXPgI1gM5BTU8yOy-Z4U)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_WSekS7cZ7T"
      },
      "source": [
        "## Задача: классификация твитов по тональности\n",
        "\n",
        "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
        "\n",
        "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
        "\n",
        "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo6Z2ORzcZ7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28263664-b9e3-4bed-8bbc-eb615b37234a"
      },
      "source": [
        "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
        "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
        "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-09 18:10:17--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/6mg7rw3wltux83q2o4ah4/positive.csv?rlkey=cvruhzofza9kkfxwzyp2vskfd [following]\n",
            "--2024-09-09 18:10:18--  https://www.dropbox.com/scl/fi/6mg7rw3wltux83q2o4ah4/positive.csv?rlkey=cvruhzofza9kkfxwzyp2vskfd\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc2954d258b9e402f5b459bf182d.dl.dropboxusercontent.com/cd/0/inline/CaSyUN9p0FRCU5XVaNPnHK5tk3j5z6-zMPTS8Meu2izLDPvEsBLgTukuYGQE5FlhIduRMz1WJohHySQ5_dImMXjws4vob6sm-fcsAPdP4Q2hchk2532cVdlokobH4Ul3NI8/file# [following]\n",
            "--2024-09-09 18:10:19--  https://uc2954d258b9e402f5b459bf182d.dl.dropboxusercontent.com/cd/0/inline/CaSyUN9p0FRCU5XVaNPnHK5tk3j5z6-zMPTS8Meu2izLDPvEsBLgTukuYGQE5FlhIduRMz1WJohHySQ5_dImMXjws4vob6sm-fcsAPdP4Q2hchk2532cVdlokobH4Ul3NI8/file\n",
            "Resolving uc2954d258b9e402f5b459bf182d.dl.dropboxusercontent.com (uc2954d258b9e402f5b459bf182d.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uc2954d258b9e402f5b459bf182d.dl.dropboxusercontent.com (uc2954d258b9e402f5b459bf182d.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26233379 (25M) [text/plain]\n",
            "Saving to: ‘positive.csv’\n",
            "\n",
            "positive.csv        100%[===================>]  25.02M  11.6MB/s    in 2.2s    \n",
            "\n",
            "2024-09-09 18:10:22 (11.6 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
            "\n",
            "--2024-09-09 18:10:22--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.dropbox.com/scl/fi/wui0xz78kpna56690uej4/negative.csv?rlkey=309xeou9u3rtbejw9stb13wfr [following]\n",
            "--2024-09-09 18:10:22--  https://www.dropbox.com/scl/fi/wui0xz78kpna56690uej4/negative.csv?rlkey=309xeou9u3rtbejw9stb13wfr\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc014e144c38108157ebf8930f7.dl.dropboxusercontent.com/cd/0/inline/CaQBU74kNYufpLZbqDHyMJfLT0GRSjFiZruQCjJ-fYRLViGUhm6HBPTXvDp1yUT6Hnx41Z5NxkwboPBDRN5xamPsv7I1uQifa3djgA_cpo573Ag3mBOptXxPebiPIX32mTM/file# [following]\n",
            "--2024-09-09 18:10:23--  https://ucc014e144c38108157ebf8930f7.dl.dropboxusercontent.com/cd/0/inline/CaQBU74kNYufpLZbqDHyMJfLT0GRSjFiZruQCjJ-fYRLViGUhm6HBPTXvDp1yUT6Hnx41Z5NxkwboPBDRN5xamPsv7I1uQifa3djgA_cpo573Ag3mBOptXxPebiPIX32mTM/file\n",
            "Resolving ucc014e144c38108157ebf8930f7.dl.dropboxusercontent.com (ucc014e144c38108157ebf8930f7.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to ucc014e144c38108157ebf8930f7.dl.dropboxusercontent.com (ucc014e144c38108157ebf8930f7.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24450101 (23M) [text/plain]\n",
            "Saving to: ‘negative.csv’\n",
            "\n",
            "negative.csv        100%[===================>]  23.32M  96.6MB/s    in 0.2s    \n",
            "\n",
            "2024-09-09 18:10:24 (96.6 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw5R6bvGcZ8i"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-YuDuo8cZ9K"
      },
      "source": [
        "# считываем данные и заполняем общий датасет\n",
        "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
        "positive['label'] = ['positive'] * len(positive)\n",
        "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
        "negative['label'] = ['negative'] * len(negative)\n",
        "df = pd.concat([positive,negative])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0kATS9XcZ-N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "34d5f2e9-9cea-4f1b-88d8-e792ec28e879"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text     label\n",
              "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
              "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
              "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
              "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
              "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a741b34-f828-40f5-8ada-a8b0d9c4e6f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>111918</th>\n",
              "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111919</th>\n",
              "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111920</th>\n",
              "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111921</th>\n",
              "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111922</th>\n",
              "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a741b34-f828-40f5-8ada-a8b0d9c4e6f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a741b34-f828-40f5-8ada-a8b0d9c4e6f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a741b34-f828-40f5-8ada-a8b0d9c4e6f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-52365be7-4208-494a-9823-fd0ad1b8f956\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52365be7-4208-494a-9823-fd0ad1b8f956')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-52365be7-4208-494a-9823-fd0ad1b8f956 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0441\\u043a\\u0443\\u0447\\u0430\\u044e \\u0442\\u0430\\u043a :-( \\u0442\\u043e\\u043b\\u044c\\u043a\\u043e @taaannyaaa \\u0432\\u043f\\u0440\\u0430\\u0432\\u043b\\u044f\\u0435\\u0442 \\u043c\\u043e\\u0437\\u0433\\u0438, \\u043d\\u043e \\u044f \\u0432\\u0441\\u0435 \\u0440\\u0430\\u0432\\u043d\\u043e \\u0441\\u043a\\u0443\\u0447\\u0430\\u044e\",\n          \"\\u0422\\u0430\\u043a\\u0441\\u0438 \\u0432\\u0435\\u0437\\u0435\\u0442 \\u043c\\u0435\\u043d\\u044f \\u043d\\u0430 \\u0440\\u0430\\u0431\\u043e\\u0442\\u0443. \\u0420\\u0430\\u0437\\u0434\\u0443\\u043c\\u044b\\u0432\\u0430\\u044e \\u043f\\u0440\\u0438\\u043f\\u043b\\u0430\\u0442\\u0438\\u0442\\u044c, \\u0447\\u0442\\u043e\\u0431\\u044b \\u043c\\u0435\\u043d\\u044f \\u0432\\u0442\\u0430\\u0449\\u0438\\u043b\\u0438 \\u043d\\u0430 \\u043f\\u044f\\u0442\\u044b\\u0439 \\u044d\\u0442\\u0430\\u0436. \\u041b\\u0438\\u0444\\u0442\\u0430 \\u0442\\u043e \\u043d\\u0435\\u0442 :(\",\n          \"\\u0412\\u043e\\u0442 \\u0438 \\u0432 \\u0448\\u043a\\u043e\\u043b\\u0443, \\u0432 \\u0433\\u043e\\u0432\\u043d\\u043e \\u044d\\u0442\\u043e \\u0438\\u0434\\u0442\\u0438 \\u0443\\u0436\\u0435 \\u043d\\u0430\\u0434\\u043e(\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytgI330KcZ-w"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osqaPQk0cZ_T"
      },
      "source": [
        "## Baseline: классификация необработанных n-грамм\n",
        "\n",
        "### Векторизаторы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJdvwmXcZ_a"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jTvJ3pNcZ_y"
      },
      "source": [
        "Что такое n-граммы:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU7nGQhicZ_5"
      },
      "source": [
        "from nltk import ngrams"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoNSXICycaAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb9cbb21-ba64-4054-a12d-53f3247aed22"
      },
      "source": [
        "sent = 'Если б мне платили каждый раз'.split()\n",
        "list(ngrams(sent, 1)) # униграммы"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GyuVzrRcaBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5588caa7-3ad8-4002-d0ed-a3801b31ecd0"
      },
      "source": [
        "list(ngrams(sent, 2)) # биграммы"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б'),\n",
              " ('б', 'мне'),\n",
              " ('мне', 'платили'),\n",
              " ('платили', 'каждый'),\n",
              " ('каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS5WihstcaB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda157b4-1477-4a1b-eb16-a7dd7f9dd45f"
      },
      "source": [
        "list(ngrams(sent, 3)) # триграммы"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне'),\n",
              " ('б', 'мне', 'платили'),\n",
              " ('мне', 'платили', 'каждый'),\n",
              " ('платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5yDWI_IcaCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62fa585a-9c11-4020-89f3-a338cd9fd6a0"
      },
      "source": [
        "list(ngrams(sent, 5)) # ... пентаграммы?"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
              " ('б', 'мне', 'платили', 'каждый', 'раз')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on8d-6XRcaDX"
      },
      "source": [
        "Самый простой способ извлечь признаки из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
        "\n",
        "Объект `CountVectorizer` делает простую вещь:\n",
        "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грамм во всём корпусе\n",
        "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRYceaT0caDf"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgqrGV_ycaEP"
      },
      "source": [
        "ngram_range отвечает за то, какие n-граммы мы используем в качестве признаков:<br/>\n",
        "ngram_range=(1, 1) -- униграммы<br/>\n",
        "ngram_range=(3, 3) -- триграммы<br/>\n",
        "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
        "\n",
        "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ih5TZbCcaET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6056133-5afd-4143-e44c-3169b44d668d"
      },
      "source": [
        "list(vec.vocabulary_.items())[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('какие', 142499),\n",
              " ('то', 222032),\n",
              " ('однообразные', 172438),\n",
              " ('дни', 126126),\n",
              " ('пошли', 191516),\n",
              " ('надо', 162234),\n",
              " ('внести', 113258),\n",
              " ('разнообразие', 200485),\n",
              " ('нет', 167434),\n",
              " ('наркотики', 163885)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tdvqOJbcaE3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "ab2ca538-3908-4505-8968-b87b8b50e92d"
      },
      "source": [
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_O51yvlcaFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66842ab3-8bd9-4738-bd5e-6b13aa53c8da"
      },
      "source": [
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.76      0.76     27943\n",
            "    positive       0.77      0.76      0.77     28766\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Z6ng4UcaF6"
      },
      "source": [
        "Попробуем сделать то же самое для триграмм:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwBN7AXUcaGC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "8d4f00ba-0fd5-49eb-e21f-0bd03cb97a0a"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 3))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e12eb6f77300>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1304\u001b[0m             path_func(\n\u001b[1;32m   1305\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             ]\n\u001b[0;32m--> 452\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    453\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    711\u001b[0m                                  **options)\n\u001b[1;32m    712\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    714\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    715\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    284\u001b[0m         )\n\u001b[1;32m    285\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_strength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_multiclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO2Llu21caGZ"
      },
      "source": [
        "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeEsDhIBcaGd"
      },
      "source": [
        "## TF-IDF векторизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcagy0XNcaGf"
      },
      "source": [
        "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
        "\n",
        "Как считается tf-idf:\n",
        "\n",
        "TF (term frequency) – относительная частотность слова в документе:\n",
        "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
        "\n",
        "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
        "\n",
        "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
        "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
        "\n",
        "`t` -- слово (term), `D` -- коллекция документов\n",
        "\n",
        "Перемножаем их:\n",
        "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
        "\n",
        "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом\n",
        "количестве документов, у него высокий TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KaxOlBOcaGj"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLl5Zc_2caG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3764c56-2b5a-4bb4-9403-f096618d3ca8"
      },
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.77      0.75     26663\n",
            "    positive       0.78      0.75      0.77     30046\n",
            "\n",
            "    accuracy                           0.76     56709\n",
            "   macro avg       0.76      0.76      0.76     56709\n",
            "weighted avg       0.76      0.76      0.76     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JixM3zxIcaHN"
      },
      "source": [
        "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciJyLidscaHT"
      },
      "source": [
        "## Токенизация\n",
        "\n",
        "Токенизировать -- значит, поделить текст на слова, или *токены*.\n",
        "\n",
        "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем. Поэтому лучше использовать готовые токенизаторы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZ0NrDYcaHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09eaf69e-9957-4a55-b0fa-ffb7d63db328"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zDIkXJhcaHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7398249-5b9b-4394-b7e0-c3b0e840d024"
      },
      "source": [
        "example = 'Но не каждый хочет что-то исправлять:('\n",
        "word_tokenize(example)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8jrq1kXcaH4"
      },
      "source": [
        "В nltk вообще есть довольно много токенизаторов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvBhn0wicaH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f22a0c1-520a-497d-82b6-e91a881b6b54"
      },
      "source": [
        "from nltk import tokenize\n",
        "dir(tokenize)[:16]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BlanklineTokenizer',\n",
              " 'LegalitySyllableTokenizer',\n",
              " 'LineTokenizer',\n",
              " 'MWETokenizer',\n",
              " 'NLTKWordTokenizer',\n",
              " 'PunktSentenceTokenizer',\n",
              " 'RegexpTokenizer',\n",
              " 'ReppTokenizer',\n",
              " 'SExprTokenizer',\n",
              " 'SpaceTokenizer',\n",
              " 'StanfordSegmenter',\n",
              " 'SyllableTokenizer',\n",
              " 'TabTokenizer',\n",
              " 'TextTilingTokenizer',\n",
              " 'ToktokTokenizer',\n",
              " 'TreebankWordDetokenizer']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek23QFXWcaIR"
      },
      "source": [
        "Они умеют выдавать индексы начала и конца каждого токена:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xX94e04caIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c153d6-8cd8-43c8-9220-4eacad4ce0d8"
      },
      "source": [
        "wh_tok = tokenize.WhitespaceTokenizer()\n",
        "list(wh_tok.span_tokenize(example))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl9cdF2ycaIw"
      },
      "source": [
        "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
        "\n",
        "Некторые токенизаторы ведут себя специфично:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uSIiOBacaIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80091f1-17c4-4c66-f2d3-bcd68cc3e5f9"
      },
      "source": [
        "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do', \"n't\", 'stop', 'me']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ycih5W-caJO"
      },
      "source": [
        "Для некоторых задач это может быть полезно.\n",
        "\n",
        "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmgL5JRdcaJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6829c0-ed60-4dc4-d571-da6cb4ab0414"
      },
      "source": [
        "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(a (b c))', 'd', 'e', '(f)']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DkDk49-caJo"
      },
      "source": [
        "## Стоп-слова и пунктуация\n",
        "\n",
        "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMR9eNnQcaJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bcf277f-5296-4cfd-b3f9-0a5c4539e74f"
      },
      "source": [
        "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('russian'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGb_nU-mcaKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61e994dd-3c3a-4d68-b5fc-3af16ede98f8"
      },
      "source": [
        "from string import punctuation\n",
        "punctuation"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSHmwcW9caKl"
      },
      "source": [
        "noise = stopwords.words('russian') + list(punctuation)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-pn9DadcaK5"
      },
      "source": [
        "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-xuZ4HucaK8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "c00dd80e-d5f4-4d46-ed86-ab88734c66a0"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8839256f1174>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     return [\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return [\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/destructive.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubstitution\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubstitution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Handles parentheses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/re.py\u001b[0m in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# internal: Pattern.sub/subn implementation helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# literal replacement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBonc7nCcaLM"
      },
      "source": [
        "Получилось чуть лучше. Что ещё можно сделать?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VHLHQSkcaLQ"
      },
      "source": [
        "## Лемматизация\n",
        "\n",
        "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
        "* Во-первых, мы хотим рассматривать как отдельный признак каждое *слово*, а не каждую его отдельную форму.\n",
        "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
        "\n",
        "Для русского есть как минимум два хороших лемматизатора: mystem и pymorphy (но есть и другие, например, Natasha):\n",
        "\n",
        "### [Mystem](https://tech.yandex.ru/mystem/)\n",
        "Как с ним работать:\n",
        "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
        "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXfQU1Y-caLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c905d518-25f2-4643-dffa-f6f1f6c9929a"
      },
      "source": [
        "from pymystem3 import Mystem\n",
        "mystem_analyzer = Mystem()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhXsc4D2caLi"
      },
      "source": [
        "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
        "* mystem_bin - путь к `mystem`, если их несколько\n",
        "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
        "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
        "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
        "\n",
        "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
        "\n",
        "Можно просто лемматизировать текст:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8i3HHbwcaLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df688408-8806-4c7f-a129-ab08e606dd0f"
      },
      "source": [
        "print(mystem_analyzer.lemmatize(example))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ytQs6kcaL5"
      },
      "source": [
        "А можно получить грамматическую информацию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H1UsuoRcaL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032ae44b-57d5-44bd-c0d3-129f04f35a9e"
      },
      "source": [
        "mystem_analyzer.analyze(example)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
              "  'text': 'Но'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'каждый',\n",
              "    'wt': 0.9985975799,\n",
              "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
              "  'text': 'каждый'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'хотеть',\n",
              "    'wt': 1,\n",
              "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
              "  'text': 'хочет'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
              "  'text': 'что-то'},\n",
              " {'text': ' '},\n",
              " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
              "  'text': 'исправлять'},\n",
              " {'text': ':(\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrGypyhGcaMR"
      },
      "source": [
        "Давайте теперь попробуем лемматизатор майстема в качестве токенизатора."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSDYpuJhcaMV"
      },
      "source": [
        "import re\n",
        "def my_preproc(text):\n",
        "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
        "    text = mystem_analyzer.lemmatize(text)\n",
        "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flUY2rfocaMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "3be48f3d-fc87-41fa-ae1e-b3b82a7a3f63"
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-8fbdae5300e4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_preproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-d959ae739e45>\u001b[0m in \u001b[0;36mmy_preproc\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_preproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmystem_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'russian'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymystem3/mystem.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_encode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymystem3/mystem.py\u001b[0m in \u001b[0;36m_get_lemma\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_lemma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mlemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38iCzgMocaMw"
      },
      "source": [
        "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
        "Это модуль на питоне, довольно быстрый и с кучей функций."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Ba4QAKcaMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7fb5f9-b216-44b7-b179-a8fbb322eb17"
      },
      "source": [
        "!pip install pymorphy2\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "pymorphy2_analyzer = MorphAnalyzer()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=42782918e4dfe324d0d545bca5d910e71e558a9aa9e8924d2b39c3d0583ee654\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBb0v0XCcaM_"
      },
      "source": [
        "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrBhhlTocaNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62945c0-4260-4454-df4e-6b00308c3c91"
      },
      "source": [
        "ana = pymorphy2_analyzer.parse(sent[3])\n",
        "ana"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih4ky-pzcaNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea28f21f-eb74-4cbf-a772-b14f5009ec52"
      },
      "source": [
        "ana[0].normal_form"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'платить'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R00b4vpucaNe"
      },
      "source": [
        "А теперь напишите аналогичную функцию для лемматизации с pymorphy2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Z-P69ccaNg"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prGblX94caNr"
      },
      "source": [
        "Что будет, если использовать её в качестве препроцессора?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EHMsrVJcaNu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwquMmyvcaN5"
      },
      "source": [
        "### mystem vs. pymorphy\n",
        "\n",
        "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
        "\n",
        "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZA_orFFcaN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d087e138-fbf4-48b3-fcfe-70362edc40d2"
      },
      "source": [
        "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
        "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
        "homonym3 = 'Мальчик разбил стекло в окне.'\n",
        "homonym4 = 'Мальчик разбил банку, и варенье медленно стекло со стола.'\n",
        "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
        "\n",
        "print(mystem_analyzer.analyze(homonym1)[-5])\n",
        "print(mystem_analyzer.analyze(homonym2)[0])\n",
        "\n",
        "print(mystem_analyzer.analyze(homonym3)[4])\n",
        "print(mystem_analyzer.analyze(homonym4)[-7])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
            "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n",
            "{'analysis': [{'lex': 'стекло', 'wt': 0.9853860572, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'стекло'}\n",
            "{'analysis': [{'lex': 'стекло', 'wt': 0.9853860572, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'стекло'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nATnTGScaOL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnF9jZVHcaOi"
      },
      "source": [
        "## Словарь, закон Ципфа и закон Хипса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQbetP7caOl"
      },
      "source": [
        "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhAcf6ZdcaOn"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sf0VUFMcaO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510cfde4-8f9f-435d-f775-54dec689350f"
      },
      "source": [
        "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
        "print(len(corpus))\n",
        "corpus[:10]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2870536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcstqOJ3caPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cc2d1f-63bc-4238-b1e7-e81b8ba36b3a"
      },
      "source": [
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
        "list(freq_dict_sorted)[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('не', 69472),\n",
              " ('и', 55166),\n",
              " ('в', 52902),\n",
              " ('я', 52818),\n",
              " ('RT', 38070),\n",
              " ('на', 35759),\n",
              " ('http', 32998),\n",
              " ('что', 31541),\n",
              " ('с', 27217),\n",
              " ('а', 26860)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aOt_E0_caPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "452e915c-bc79-4ffa-c713-b59ace2a7443"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
        "plt.plot(first_100_freqs)\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VES6FwDycaP1"
      },
      "source": [
        "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTYFEchDcaP4"
      },
      "source": [
        "## О важности эксплоративного анализа\n",
        "\n",
        "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет, если вообще не убирать пунктуацию?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh-V2A2LcaP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f0f572-f06c-421a-bb08-2fce2574b3bf"
      },
      "source": [
        "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00     27940\n",
            "    positive       1.00      1.00      1.00     28769\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVsg62EmcaQP"
      },
      "source": [
        "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите признаки с самыми большими коэффициентами:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791KkwrpcaQU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS2w2r4OcaQl"
      },
      "source": [
        "Посмотрим, как один из супер-значимых токенов справится с классификацией без всякого машинного обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXm6kC8BcaQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902dd948-51a2-4c54-ff3f-4809593f7eb6"
      },
      "source": [
        "cool_token = ')'\n",
        "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      0.85      0.92     32951\n",
            "    positive       0.83      1.00      0.91     23758\n",
            "\n",
            "    accuracy                           0.91     56709\n",
            "   macro avg       0.91      0.93      0.91     56709\n",
            "weighted avg       0.93      0.91      0.91     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKhGelRYcaQ8"
      },
      "source": [
        "## Символьные n-граммы\n",
        "\n",
        "Теперь в качестве признаков используем, например, униграммы символов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDVOQo_ycaRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626af702-baa1-4e1b-d3ed-693be8b12cb2"
      },
      "source": [
        "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "bow = vec.fit_transform(x_train)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(bow, y_train)\n",
        "pred = clf.predict(vec.transform(x_test))\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.99      1.00      1.00     27688\n",
            "    positive       1.00      0.99      1.00     29021\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhgl797-caRS"
      },
      "source": [
        "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или иначе, на символах классифицировать тоже можно: для некоторых задач (например, для определения языка) признаки - символьные n-граммы работают очень неплохо.\n",
        "\n",
        "Ещё одна замечательная особенность признаков-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готовых анализаторов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC34Hv70caRV"
      },
      "source": [
        "## Регулярки\n",
        "\n",
        "(если осталось время)\n",
        "\n",
        "Вообще, часто бывает так, что для конкретного случая нужен особый способ токенизации, и надо самостоятельно написать регулярку. Или, например, перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
        "\n",
        "Навык полезный, давайте в нём тоже потренируемся."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuIpMEb6caRZ"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HAkI_oFcaRu"
      },
      "source": [
        "### findall\n",
        "возвращает список всех найденных совпадений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnSmc38bcaRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a864c821-873e-40dd-aa10-e46d72e1c21d"
      },
      "source": [
        "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcd', 'abca']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI5I4rukcaSB"
      },
      "source": [
        "Вопрос на внимательность: почему нет abcx?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dgI0YGocaSk"
      },
      "source": [
        "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04a6ugT-caSm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeyVPV_HcaS0"
      },
      "source": [
        "### split\n",
        "разделяет строку по заданному шаблону\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvUViO08caS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c9ba6a-d7e2-4b2c-d96e-37c5315460b9"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie', ' weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCtZSYRacaTF"
      },
      "source": [
        "можно указать максимальное количество разбиений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G797L28YcaTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6e2152-e66d-4843-cc54-915c101468bb"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit = 2)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie, weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fydg4ioHcaTU"
      },
      "source": [
        "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSJT2coicaTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e7230d-ee02-4670-e4f5-e92aa5d8e0d0"
      },
      "source": [
        "result = re.split(',', 'apple,pear,banana')\n",
        "print ([a[0] + a[1] for a in result])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ap', 'pe', 'ba']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPPk70tjcaTi"
      },
      "source": [
        "### sub\n",
        "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
        "\n",
        "параметры: (pattern, repl, string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euUczQ9pcaTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e60b8e-7f1f-457d-fd25-4200be54401d"
      },
      "source": [
        "result = re.sub('a', 'b', 'abcabc')\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbcbbc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ-9QA5tcaTw"
      },
      "source": [
        "**Задание**: напишите регулярку, которая заменяет все цифры в строке на \"DIG\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1sQlaDWcaTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3865ef-d6ab-4e83-b74e-ab6228e5cf85"
      },
      "source": [
        "result = re.sub('\\d', 'DIG', 'abc5ab2c')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcDIGabDIGc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qld28QPkcaT-"
      },
      "source": [
        "**Задание**: напишите регулярку, которая убирает url из строки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CogHtkUCcaUA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej-my8jacaUK"
      },
      "source": [
        "### compile\n",
        "компилирует регулярное выражение в отдельный объект"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUNF3LC8caUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e582d5-4f67-45d6-f2f7-77e3ae6485b4"
      },
      "source": [
        "# Пример: построение списка всех слов строки:\n",
        "prog = re.compile('[А-Яа-яё\\-]+')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv_oyL62caUb"
      },
      "source": [
        "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5qlsN-EcaUe"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hPLs3XkcaUv"
      },
      "source": [
        "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
        "\n",
        "```\n",
        "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCMRHxajcaUz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgzNJpFtcaV4"
      },
      "source": [
        "Если всё ещё осталось время: [регулярочный кроссворд ¯\\_(ツ)_/¯](https://mariolurig.com/crossword/)"
      ]
    }
  ]
}